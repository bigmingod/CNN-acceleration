Deep Compression
1 Introuction
深度神经网络已经发展成最先进的技术在计算机视觉领域。尽管神经网络很有效，但是大量权重的的数字消耗了值得注意的存储和内存带宽。例如，ALexnet caffemodel超过了200M，VGG-16超过500M。这使得在移动系统中部署神经网络很困难。
首先，对许多移动为主的公司如百度和脸书来说，大量的app通过不同的app store来更新，而且他们对二进制文件的大小很敏感。例如，appstore有一个限制，超过100M的app在wifi下才能下载。作为结果，使得二进制文件增大超过100M的特点会得到更多的仔细审查比起增加10M的特点。尽管深度神经网路在移动设备上有很多优势比如隐私性、更少的网络带宽和实际的处理时间，但是大量的存储需求使得深度神经网络不能并入移动设备。
第二个问题是能源消耗。运行庞大的神经网络需要大量的存储带宽来获取权值和大量的计算得到点积（内积）的结果——这反过来消耗了很多能源。移动设备的电量有限，使得消耗能源的应用比如深度神经网络不能够部署。
下一段是能源消耗的例子。
我们的目标是减少大型网络运行所需的存储和能源需求，所以他们就可以部署在移动设备上了。为了达到这个目的，我们呈现了“深度压缩”：一个三阶段流水线（图1）来减少神经网络的存储需求，同时保证原来的准确度。首先，我们对网络进行剪枝，通过移除荣誉的连接，只保留信息最多的连接。然后，权值被量化所以多重连接可以分享相同的权值，因此只有有效权值和指数需要被存储。最后，我们用huffman编码来利用有效权值的不均分配。
我们主要看法是，剪枝和训练量化能够压缩网络而不互相影响，由此可以导致很高的压缩率。这使得需要的存储很小（几MB）以至于所有的权重可以缓存在芯片上，不需要在能源消耗大的DRAM上。以深度压缩为基础，EIE硬件加速（其他论文）后来提出在压缩好的模型的作品，达到了很好的加速率和能源效率的改进。

2 网络剪枝
网络剪枝广泛使用在压缩CNN模型中。早期的研究中，网络剪枝被证明有效地降低网络复杂度和过度拟合。最近我们剪枝了先进的CNN模型而不损失精确度。我们以此为基础。图一左边所示，我们开始通过普通的网络训练来学习连接。然后，我们剪掉小权值的连接：所有在阈值以下的有权值的连接都从网络除去了。最终我们限制网络学习最终的权重为了剩余的稀疏连接。剪枝减少了参数数量分别是9倍的ALexnet和13倍的VGG16。
我们将剪枝得到的稀疏结构用压缩稀疏行或压缩稀疏列的形式存储，需要2a+n+1个数字，a是非零元素个数，n是行数或者列数。
为了进一步压缩，我们存储指数的差而不是绝对位置，编码这个差异，卷积层8bit，fc层5bit。当我们需要一个指数差异大于边界，我们用图二所示的零填充的方法防止差异插队8,以最大为3bit的无符号数为例，我们填上一个0。



3 训练量化和权值共享
网络量化和权值共享进一步压缩了剪枝后的网络，通过减少需要表示每个权重的bit的数量。我们限制我们需要存储的有效权值的数量，通过多个连接共享一个权重，然后精细地协调这些共享的权值。
权值共享在图3所示。假设我们有一个层，4个神经输入和四个神经输出，权值是4×4矩阵。图3左上是权值矩阵，左下是梯度矩阵。权值被分成4组（4种颜色代表），同一组中的所有权值共享同一值，所以对每一个权值，我们需要存储一个索引到共享权值的表。在更新中，所有的梯度值被分组（通过颜色）并加到一起，乘以学习率，被上一次迭代的共享矩阵心（？）减去。对于剪枝的ALexnet，我们可以量化8bit
对每一个卷积层，5bit对每一个fc层而不损失精确度。
为了计算压缩率，给定k个族，我们需要logk个位来编码索引。大体上，对一个有n个来连接的网络，每个连接由b个bit表示，限制连接有k个共享权值会得到这样的压缩率。例如图3中每个单层神经网络的权值有4个输入4个输出，起初有16个权值但是只有4个共享权值：相近的权值被组织到一起共享相同的权值。起初我们需要存储16个权值每个32bit，现在我们需要存储4个有效权值，每个32bit，和16个2bit的索引，压缩率为3.2。
3.1 权值共享
我们用k-means分组来等同训练的网络的每一层的共享权值，所以进入相同的组的所有权值共享同一个的权值。层之间的权值不是共享的。我们把n个原始的权值W分入k个族群C，n>>k,所以使得组内偏差尽可能小。不同于hashnet里权值共享由一个哈希函数决定，在网络实际看到任何训练数据之前，我们的方法决定权值共享实在网络已经充分训练之后，所以共享的全值接近原始网络。
3.2 权值的初始化
矩心的初始化影响了分组的质量也因此影响了网络预测的准确度。我们检查了三种初始化方法：随机，密度基础、线性初始化。图4中哦我们描述了原始权值分布在网络剪枝之后。在下面描绘了有效权值（矩心）用3中不同的初始化方法。这个例子中有13个组。
forgy：随机初始化选择了数据集中k个数据用他们来作为初始值。黄色表示。双峰分布中有两个峰值，forgy方法趋向于在两个峰值附近集中。
密度基础：初始化线性选择y轴上的值，找到了水平的和cdf交点，最终找到垂直x轴的截矩，这就是一个矩心。蓝色点所示。这个方法使得矩心更稠密在双峰处，但是比forgy分散。
cdf是概率分布函数 pdf是概率密度函数
线性:初始化在最小值到最大值的区间内线性分配初始权值。初始化方法与权值的分布无关，比起前两个方法是最分散的。
较大的权重比小权值作用更大。但是大权重很少。所以前两种方法，很少有矩心有很大的绝对值，造成对大权重很少的不好的表示。但是线性初始化没有这个问题，实验部分比较了不同初始化方法的准确度在分组和微调之后，显示出线性初始化是最好的。

3.3 前递和反馈
一维k个组的矩心是共享的。在前馈阶段和后向传播阶段期间查找权重表有一个间接级别。到共享权值表的索引为每个连接存储。在后向传播阶段，每个共享权值的梯度都会计算用来更新共享权值，这个过程在图3中展示了。
我们计损失为L，Wij，Iij，Ck。用示性函数。矩心的梯度可以这样计算。

4 huffman编码
huffman编码是最有前缀编码通常在无损数据压缩中使用。他用变长编码字段编码符号。表格是从每个标志的出现概率产生的。出现越多，编码位数越少。
图5显示了量化权值的概率分配和稀疏矩阵到全连接层的索引在alexnet中。两种分配都是不均的：量化的权值更多的分配在双峰中，稀疏矩阵索引差异很少超过20。实验显示了huffman编码这些不一致的权值分配可以节省20%-30%的网络存储。





























